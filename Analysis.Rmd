---
title: "Choice-based conjoint analysis"
output:
  html_notebook: default
  html_document:
    df_print: paged
  word_document: default
---
```{r}
# Loading the requireed libraries
library(mlogit)
```

# Choice-Based Conjoint Anlysis

In the following R Markdown, a dataset containing the answers of a choice-based conjoint survey is analyzed in order to understand the preferences of customers relatively to the Trading Apps. 

## Data Exploration. 
Let's start by loading the dataset 
```{r}
df <- read.csv('C:/Users/alber/Desktop/UniTn/Data Science/Third Semester/Laboraotry of Business and Customer analytics/Project_Real/survey_results.csv')
```
Now that the dataset is loaded, it is possible to do a bit of data exploration. 
```{r}
dim(df)
```
The dataset  contains 1007 observations and 12 columns.
```{r}
names(df)
```
The above are the names of the columns of the dataset. 
We can drop `X` which is a simple and unuseful index. 
```{r}
df <-  df[,-c(1)]
```
Now it is possible to a closer look to the data. 
```{r}
summary(df)
```
Let's see how many respondents have participated to the survey and how many questions there were. 
```{r}
max(unique(df$resp.id))
max(unique(df$ques))
```
36 possible customers have participated to the survey and they have answered to 12 questions.

Let's compute the descriptive statistics 
```{r}
xtabs(choice ~ Platform, data=df)
xtabs(choice ~ Deposit, data=df)
xtabs(choice ~ Fees, data=df)
xtabs(choice ~ Financial_Instrument, data=df)
xtabs(choice ~ Leverage, data=df)
xtabs(choice ~ Social_Trading, data=df)
xtabs(choice ~ position, data=df)

```
Now, it is possible to re-code some variables
```{r}
df$Platform <- as.factor(df$Platform)
df$Deposit <-  as.factor(df$Deposit)
df$Fees <-  as.factor(df$Fees)
df$Financial_Instrument <-  as.factor(df$Financial_Instrument)
df$Leverage <-  as.factor(df$Leverage)
df$Social_Trading <-  as.factor(df$Social_Trading)
```

### Logistic Regression 


Before performing the choice-based conjoint analysis is interesting to see how a simple logistic model would perform and which results it will provide.
```{r}
glm.fits <-  glm(choice ~ Platform + Deposit + Fees + Financial_Instrument + Leverage + Social_Trading, data = df, family = 'binomial')
summary(glm.fits)
```
From this first result, it is possible to see that `Financial_InstrumentETFs` is the two most important predictor together with the intercept.  Then follow `PlatformMobile App`, `PlatformWeb App`, `Financial_InstrumentStocks`. Lastly, `Deposit100` and `Social_TradingYES` are close to the threshold of significance. 
<br>


However, from the above summary we can start to have a partial idea of what could be the key attributes for understanding consumers' preferences. The above results although, partial and not statistically appropriate, give a useful hint. Indeed, it is reasonable to think that the financial instrument available on the trading app plays a central role in customers preferences. As a matter of fact, users will use that specific  instrument to make their financial operations. The choice of EFTs could be justified by the fact that users prefer a less volatile product and so less risky product when they chose to do trading or investments. 
Let's now give a closer look to the coefficients. 
```{r}
summary(glm.fits)$coef
```
The order of magnitude of the estimates provides how strong preferences are. However, there are not particularly high values. By the way, it is interesting to notice that ETFs are associated to an high positive coefficient while Cryptos are associated to a really low coefficient. Moreover, Cryptos have also a relatively high standard error. This may suggest the existence of a niche of customers who are less risk averse and prefer this financial instrument. 
Then, we notice that all the  negative coefficients are associated to higher values for fees or deposit. Also this result seems to be reasonable since customers do like higher fees and do not want to have a high threshold when starting to invest. 
<br>


However, it is important to state once again that these results are partial and they should not be trusted. Further analysis are needed to assess customers preferences.
Thus, to better understand customers preference is needed a more complex model that takes into account both a population-level effect and an individual level effect jointly.

## Choice Model 
Let's define a unique index for the data.
```{r}
df$resp.id.ques <- paste(df$resp.id, df$ques, sep="_")
```
Then, it is possible to drop `ques` and `resp.id`.
```{r}
df[,'resp.id'] <-  df[,'resp.id.ques']
df <- df[,-c(2,12)]
```
It is now time to fit a choice model. In order to do this, it is necessary to transform the dataset. 
```{r}
df.mlogit <- dfidx(df, idx = list("resp.id", "position"))
```
Now that the dataset is ready we can fit the choice model.
```{r}
m1 <- mlogit(choice ~ Platform + Deposit + Fees + Financial_Instrument + Leverage + Social_Trading, data = df.mlogit)
summary(m1)
```
From the summary of the model, it is possible to see coherence with the results of the previous simple logistic model. Indeed, the important variables are still the same as before.
The most important predictor refers to `Financial_InstrumentETFs` followed by `PlatformMobile App`, `PlatformWeb App`, `Deposit100`, `Financial_InstrumentStocks` and `Social_TradingYES`. 

<br>


The Estimate column provides the estimated average part worths for each level. They have to be interpreted with respect to the reference level of each attribute. It is also important to remember that the order of magnitude of the estimates provides how strong the preferences are. Moreover, the MNL model coefficients are on the logit scale and so they range mainly between -2 and 2. 
<br>


When looking at the estimates it is important to look at the sign of the coefficients together with the values to better understand the results. For example, the highest values is related to ETFs as financial instruments, this strength the initial hypothesis that this is the preferred option for customers. It is more than twice the value associated to stocks.  
Moreover, it is also interesting to notice the type of platform. Indeed, customers prefer the mobile app compared to the web app and desktop app. Also this results seems reasonable. Indeed, it is possible to hypothesize that having a mobile app allows to easily check investments. 
<br>
Deposit 100€ seems to be a relatively important predictor, with a negative coefficient. This results could be explained by hypothesizing that customers are still reluctant with this kind of product or at least they do not trust them that much to start investing 100 euros. 
<br>

Lastly, before considering the standard error, it is nice to notice that all the variables associated to higher fees have negative coefficients but they are not significant. This suggests that customers do not like higher 'fees' but they are not determinant for their choices. This can be justified by the fact that these fees are relatively low e.g. 0.015% or 0.025%. However, from the business point of view this can be a precious information because the firm could introduce small fees that gain their revenues without losing customers. 
<br>


Moving on to the standard error, it is possible to notice that these values are relatively quite high. This is definitely not a good sign. This is caused by the low number of observations and the high number of attributes in the conjoint survey. Hence, there is the need to be careful in assessing the results of this analysis because the precision of them is quite low. This can be noticed also by looking at the McFadden $R^2$. 

<br>


The intercepts, that represent the so-called _alternative specific constants_  represent the effect of the position of the options. Namely, how much customers prefer the middle/bottom alternative instead of the top one. However, from the summary it is possible to see that customers are not affected by the position of the alternatives. This is good because it means that respondents sees to have replayed rationally/properly. Thus, in order to gain in parsimony and precision, it could be checked, through a likelihood ration test, if it is necessary to include or not the intercepts in the model.
```{r}
# Fit the model without intercept parameters
m2 <- mlogit(choice ~ Platform + Deposit + Fees + Financial_Instrument + Leverage + Social_Trading |-1, data = df.mlogit)
summary(m2)
```
From the above summary, it is possible to see that there is no substantial difference among the two models in terms of magnitude of coefficients, standard error and significance.
<br>

Let's now test the restriction on the intercepts by comparing the two models through a likelihood ratio test.
```{r}
lrtest(m2, m1)
```
The comparison between the full model and the smaller model with no intercept leads to a p-value of 0.3184. According to this relatively big value, it is possible to conclude that the two models are not significantly different in terms of goodness of fit and hence they explain the data equally well. This indicates that the alternative specific constants are not necessary to adequately model the data. 

### Willingness to Pay 
For this kind of product there is not variable associated to price. Indeed, this kind of product typically do not have prices due to the fact that companies earn on fees and commissions. However, it could be interesting to consider as a kind of price the deposit namely, the amount of money needed to start investing with the app. In the survey there were three options 0€, 10€ and 100€. 
<br>

Until this point of the analysis the deposit has been considered as a qualitative variable due to its limited number of levels. 
```{r}
# Fit the model with deposit as numerical 
m3 <- mlogit(choice ~ Platform + as.numeric(as.character(Deposit)) + Fees + Financial_Instrument + Leverage + Social_Trading |-1, data = df.mlogit)
summary(m3)
```
The results are similar to the one provided by `m2`, the model without intercept. 
<br>
Since the model that treats the deposit attribute as a categorical variable would
be a nested subset of the initial model, we can perform a likelihood ratio
test to assess if including deposit as quantitative would fit the data equally
well. 
```{r}
lrtest(m3, m2)
```
According to the likelihood ratio test there is no substantial difference hence, we prefer the model that considers deposit as a numerical variable both in terms of interpretation and performance since we gain one degree of freedom. 
```{r}
coef(m3)
```
```{r}
coef(m3)/(coef(m3)["as.numeric(as.character(Deposit))"])
```
Given as reference level a trading app which has as platform the desktop, zero fees, commodities as financial instrument and without leverage and social trading, we get that customers will respectively accept an increase in the deposit of:
* 108 euros for having the app in mobile version;
* 88 euros for having the app in web version;
* -11 euros for having fees at 0.015%;
* -52 euros for having fees at 0.025%;
* 24 euros for having criptos as financial instrument;
* 230 euros for having ETFs as financial instrument;
* 130 euros for having stocks as financial instrument
* 34 euros for the leverage 
* 66 euros for having the possibility to do social trading


### Simulating preference Shares

Besides the willingness-to-pay measure, another useful approach to assess the role of product attributes consists on using the model to obtain preference share predictions. This can be useful for firms when they have to launch new products on the market in order to have an __idea__ of what could be the market share. 

```{r}
predict.mnl <- function(model, data) {
  # Function for predicting preference shares from a MNL model 
  # model: mlogit object returned by mlogit()
  # data: a data frame containing the set of designs for which you want to 
  #       predict shares.  Same format at the data used to estimate model. 
  data.model <- model.matrix(update(model$formula, 0 ~ .), data = data)[,-1]
  logitUtility <- data.model%*%model$coef # to extract the vector of exstimated parameter.
  share <- exp(logitUtility)/sum(exp(logitUtility))
  cbind(share, data)
}
```


```{r}
# Create a combination of all possible products 
attributes <- list(Platform=names(table(df$Platform)),
               Deposit =names(table(df.mlogit$Deposit)),
               Fees=names(table(df.mlogit$Fees)),
               Financial_Instrument=names(table(df.mlogit$Financial_Instrument)),
               Leverage=names(table(df.mlogit$Leverage)),
               Social_Trading=names(table(df.mlogit$Social_Trading)))
allDesign <- expand.grid(attributes) 
```
First look at `allDesign`
```{r}
allDesign
```
According to the results obtained until now, it seems that the best trading app has the following attributes: 
* Platform = Mobile;
* Fees = 0 
* Deposit = 0 
* Finanacial_Instrument = ETFs
* Leverage = YES
* Social_Trading = YES
This product profile corresponds to the observation 380 of `allDesign`. 
The other product profiles in `new.data` have been chosen randomly. 

Thus, it is interesting to see how this product would be perceived according to the two model.
```{r}
# Chose a random sample of product in order to compute their preference share
new.data <- allDesign[c(380, 118, 214, 32, 300, 356), ]
new.data
```
Let's compute the __preference shares__. 
```{r}
predict.mnl(m3, new.data)# using m3 specification

```
```{r}
predict.mnl(m2, new.data)
```
The chosen product profiles seems to be preferred by the most preferred product among the others. Indeed, according to `m2` it has the 41% of the preference shares while according to `m3` it has the 42% of preference shares. However, this is just an example and does not reflect the real world. Firstly, because the products reflects the average preferences of the survey respondents but it does not mean that they are the same of the sample of all potential customers. Moreover, there could be the possibility that realizing that specific product is not economically sustainable for the firm.  

Again, it always important to understand the data and to not over-read them. Indeed, the above results __do not reflect the real world and the real market shares__. 
<br>
Firstly, it is important to be aware that these predicted shares are made relative to a specific given set of potential competitors. 
<br>
Moreover, it is important to _not treat the obtained preference share predictions as actual market share forecasts_. Indeed, these predictions represent the respondents behavior in a survey context but they do not necessarily translate to actual sales in real marketplace. 
For example, it could be difficult for a customer to find in the market the trading app with all the characteristics that he/she likes the most. Moreover, it is always important to remember that customers may _behave differently_ when they have to make a _real-life decision_ that involve money. 
<br>
Nevertheless, these _preference shares_ can be useful to companies in order to get at least partially understanding of the potential customers' preferences.  

### Sensitivity chart
From a business perspective it could be useful to predict how the preference share for the planned product design would change if variations on the levels of the attributes were considered. 

```{r}
sensitivity.mnl <- function(model, attrib, base.data, competitor.data) {
  # Function for creating data for a preference share-sensitivity chart
  # model: mlogit object returned by mlogit() function
  # attrib: list of vectors with attribute levels to be used in sensitivity
  # base.data: data frame containing baseline design of target product
  # competitor.data: data frame contining design of competitive set
  data <- rbind(base.data, competitor.data)
  base.share <- predict.mnl(model, data)[1,1]
  share <- NULL
  for (a in seq_along(attrib)) {
    for (i in attrib[[a]]) {
      data[1,] <- base.data
      data[1,a] <- i
      share <- c(share, predict.mnl(model, data)[1,1])
    }
  }
  data.frame(level=unlist(attrib), share=share, increase=share-base.share)
}
```
However, before applying the above function, new `new.data` has been created. Indeed, by using the previous sample of product profiles the result will be a plot where all the bar are above 0 (negative values). This will occur because the first product profile has the best attributes according to the respondents' taste. Then it would be meaningless creating a sensitivity plot. 

```{r}
# Chose a random sample of product in order to compute their preference share
new.data<- allDesign[c(100, 118, 214, 32, 248, 356), ]
new.data
```

```{r}
base.data <- new.data[1,]
competitor.data <- new.data[-1,]
(tradeoff <- sensitivity.mnl(m2, attributes, base.data, competitor.data))
# Tradeoff -> how preferences change
# This allows to assess the strength of the effect of the attributes in a more efficient way. 


barplot(tradeoff$increase, horiz=FALSE, names.arg = c('Desktop', 'Mobile', 'Web', '0€', '10€', '100€', '0%', '.015%', '.025%', 'Comm', 'Crypto', 'EFT', 'Stocks', 'LevN', 'LevY', 'STN', 'STY' ),
        ylab="Change in Share for the Planned Product Design", 
        ylim=c(-0.1,0.11), main = 'Sensitivity Chart')
grid(nx=NA, ny=NULL)
```
The above __Sensitivity Chart__ for trading app design with Desktop as platform, 0€ for the deposit, fees at 0.025%, Stocks as financial instrument and without leverage and social trading.
When a company analysis this data, there is always a trade off between costs and potential revenues. For example, realizing a product with specific attributes could be more expensive but there could be an increase in the preference share that counterbalance that costs. 
For example in this context, a decrease in the fees produces a small increase in preference shares but this loss could be accepted if it is payed off by the revenues related to the fees. 

#### 95% C.I.

In order to have an higher degree of confidence, instead of looking at fixed values for preference shares it is better to compute a confidence interval. 
```{r}
library(parallel)

dataModel <- m2$model
dataModel$probabilities <- NULL
dataModel$linpred <- NULL
idx <- dataModel$idx 
dataModel$idx <- NULL
dataModel <- data.frame(dataModel, idx)
idVar <- unique(dataModel[,names(idx)[1]])

bootstrapping <- function(x) {
  idbootsamp <- data.frame(sample(idVar, replace=T))
  names(idbootsamp) <- names(idx)[1]
  bootsamp <- merge(idbootsamp, dataModel, by=names(idx)[1], all.x=T)
  bootsamp[,names(idx)[1]] <- rep(1:length(table(idx[,1])), each=length(table(idx[,2])))
  bootsamp.mlogit  <- dfidx(bootsamp, idx =  list("resp.id", "position"))    
  bootfit <- update(m2, data = bootsamp.mlogit)
  data.model <- model.matrix(update(bootfit$formula, 0 ~ .), data = new.data)[,-1]
  logitUtility <- data.model%*%bootfit$coef
  share <- exp(logitUtility)/sum(exp(logitUtility))
  share
}

cl <- makeCluster(detectCores())
  clusterEvalQ(cl, library(mlogit))
  clusterExport(cl, varlist=c("idVar", "dataModel", "idx", "m2", "new.data"), 
                envir=environment())
  bootdistr <- parLapply(cl, 1:500, fun=bootstrapping)
stopCluster(cl)

bootdistr <- do.call(cbind, bootdistr)
lowl <- (1-0.95)/2
upl <- 1-lowl  
bootperc <- t(apply(bootdistr, 1, function(x) quantile(x, probs=c(lowl, upl))))
pointpred <- predict.mnl(m2, new.data)
predictedShares <- cbind(pointpred[,1], bootperc, pointpred[,2:ncol(pointpred)])
names(predictedShares)[1] <- "share" 
predictedShares
```

In the above table it is possible to see the 95% Confidence Interval for the preference shares of `m2` relatively to the sample of data named as `new.data`. Typically, computing the confidence interval gives useful information to firms because they can get a less rigid idea of what could be the preference shares of customers. 

### Dealing with Consumer Heterogeneity

Until now the analysis was based on the average part worths. However, it is important to consider that could exist some niches in the market and that customers can have heterogeneous preferences.  Hence, it is reasonable to use the mixed MNL model in order to assess a unique coefficient to each respondent. This should increase the goodness of fit and provide more accurate preference share predictions that models with fixed effects. 

```{r}
# assuming that all coefficients are normally distributed across the population
m2.rpar <- rep("n", length=length(m2$coef))
names(m2.rpar) <- names(m2$coef)
m2.rpar
```

```{r}
m2.mixed <- mlogit(choice ~ Platform + Deposit + Fees + Financial_Instrument + Leverage + Social_Trading |-1, data = df.mlogit, rpar = m2.rpar, correlation = F)
summary(m2.mixed)
```
Before, analyzing the model it is important to state that it was not possible to compute the model by passing the parameter `panel = T`. Hence, the results are more difficult to compare with respect to the ones of the previous models. 
However, from the summary of the _mixed MNL model_, it is possible to notice that the standard deviation for many variables is high meaning that there is __high heterogeneity in customers preferences__.
Moreover, by looking at the table `random coefficients`, which provides summary measures for each distribution of the individual-level coefficients we notice that a change of sign occurs frequently. This is another sign of __heterogeneity in customers preferences__. 
The variable with the largest distribution is definitely `Financial_InstrumentCrypto` followed by `Social_TradingYES` and `Leverage YES`. 
Then it is possible to hypothesize that, among the respondents, there is a subset of people that feel more confident with finance and investments and so are more prone to use more complex financial instruments such as cryptos and in using the financial leverage in order to try to boost their investments. With respect to  `Social_TradingYES` it is possible to assume that the majority of people prefer to have it but other may be just indifferent and do not look for this kind of feature. However, from a business point of view it is better to include it in the product also because is not mandatory to use it, the same holds for the leverage. On the other hand, the trading app could include more financial products in order to satisfy any customer. 


```{r}
lrtest(m2, m2.mixed)
```
According to the test the new model specification significantly reduce the goodness of fit. Hence we should keep the model `m2` as the reference point. 

#### Adding correlation to the mixed MNL model 
In addition, it is possible to allow the random coefficients to be correlated. This permits to assess whether customers who favor one attribute also tend to favor another attribute. 
In this way there is a loss of degree of freedom but the results should be more reliable and interpretable.

```{r}
m2.mixed2 <- update(m2.mixed, correlation = TRUE)
summary(m2.mixed2)
```

```{r}
# It is difficult to interpret covariances
cov.mlogit(m2.mixed2)
```

```{r}
cov2cor(cov.mlogit(m2.mixed2))
```

```{r}
summary(vcov(m2.mixed2, what = "rpar", type = "cor"))
```
According to the above table just a couple of correlations are significant: `cor.PlatformMobile App:Deposit10 ` and `or.PlatformWeb App:Deposit100`. However, it is difficult to interpret and give a meaning to these results. So, in this case it is better to not hazard any conclusion also because the number of respondents and the observation used for the analysis are probably not enough. 


```{r}
lrtest(m2, m2.mixed2)
```
Again, the results of the test show that the best model remains `m2`.  Hence there is no need to compute the preference share of the mixed MNL models. 

### Respondent level variable and customer heterogeneity 

During the survey has also been collected demographic data. Unfortunately, the sample group seems to be quite homogeneous with respect to education level, nationality, job sector and age, there are just few outliers. However, one discriminant factor could be the gender. Hence, it could be interesting to notice if the differences in the preferences could be related to the gender. For example, according to the literature on risk perception men seem to be less risk averse compared to women. This could partially explain some of the results related to the preference of the financial product. 

```{r}
m4.mixed <-  mlogit(choice ~ Platform + Deposit + Fees + Financial_Instrument + Leverage + Social_Trading | Gender, data = df.mlogit, panel = F,rpar = m2.rpar, correlation = F)
summary(m4.mixed)
```
According to the results that we get there is no difference among males and females. This model does not provide useful information. 
